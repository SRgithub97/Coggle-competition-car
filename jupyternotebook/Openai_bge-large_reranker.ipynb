{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lg20GgWxJwso"
   },
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1708169396477,
     "user": {
      "displayName": "Shirley Lin",
      "userId": "14721665985824307871"
     },
     "user_tz": -480
    },
    "id": "CKQYdCW3RcMZ"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1708167503095,
     "user": {
      "displayName": "Shirley Lin",
      "userId": "14721665985824307871"
     },
     "user_tz": -480
    },
    "id": "bzVonL9yQ8yd"
   },
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-hj7x7P9fjFb6gC63AaC78aAaA56b4814A864EcA243A6B100\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://ai-yyds.com/v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phGJxU2nJ0p2"
   },
   "source": [
    "### RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qUlHLSwkf6ED",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 405,
     "status": "ok",
     "timestamp": 1708168458827,
     "user": {
      "displayName": "Shirley Lin",
      "userId": "14721665985824307871"
     },
     "user_tz": -480
    },
    "id": "5rzC4dg-Jp1K"
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 8937,
     "status": "ok",
     "timestamp": 1708168469626,
     "user": {
      "displayName": "Shirley Lin",
      "userId": "14721665985824307871"
     },
     "user_tz": -480
    },
    "id": "D9_ODkxPJsum"
   },
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"/gemini/data-1/初赛训练数据集.pdf\")\n",
    "data=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 469,
     "status": "ok",
     "timestamp": 1708168484548,
     "user": {
      "displayName": "Shirley Lin",
      "userId": "14721665985824307871"
     },
     "user_tz": -480
    },
    "id": "mjfMWLpTg0Xa"
   },
   "outputs": [],
   "source": [
    "data_list=[]\n",
    "for i in range (0,len(data)):\n",
    "  page=data[i].metadata[\"page\"]\n",
    "  data[i].metadata[\"page\"]=page+1\n",
    "  if i>=2 and i<=6:\n",
    "    data[i].metadata[\"category\"]=\"catalog\"\n",
    "  else:\n",
    "    data[i].metadata[\"category\"]=\"content\"\n",
    "  if data[i].page_content!=\"\":\n",
    "    data_list.append(data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OUTFl5-kpaxW"
   },
   "source": [
    "我现在估计需要进行一下这边的预处理的工作。\n",
    "这边基本上都是没有加上任何的meta的。估计之后需要加上meta.\n",
    "注意这边的meta信息是不对的，因为这边的meta信息page是从0开始的，但是page的信息需要从1开始。所以这边有这样的一个page的更改。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_m1z5i9HN4jQ"
   },
   "source": [
    "这边我估计就是直接放弃所有的split的过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czMJ3hRhEGoO"
   },
   "source": [
    "##### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 9188,
     "status": "ok",
     "timestamp": 1708168547249,
     "user": {
      "displayName": "Shirley Lin",
      "userId": "14721665985824307871"
     },
     "user_tz": -480
    },
    "id": "K8xFpvZtQgR9"
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "vectordb = Chroma(persist_directory=\"/gemini/code/vectordb\", embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1708168547250,
     "user": {
      "displayName": "Shirley Lin",
      "userId": "14721665985824307871"
     },
     "user_tz": -480
    },
    "id": "bYd5_VW1SKRt",
    "outputId": "8ceec1f5-5f9e-4a8f-e95b-f6843db23fad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "334"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb._collection.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgWPU9Ilc3M9"
   },
   "source": [
    "#### 构建的retriever_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1708168547251,
     "user": {
      "displayName": "Shirley Lin",
      "userId": "14721665985824307871"
     },
     "user_tz": -480
    },
    "id": "O1SUefOkVNGS"
   },
   "outputs": [],
   "source": [
    "retriever_k =vectordb.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaForSequenceClassification(\n",
       "  (roberta): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 1024, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): XLMRobertaClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('/gemini/pretrain2')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('/gemini/pretrain2')\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_documents(query):\n",
    "    results=retriever_k.get_relevant_documents(query)\n",
    "    doc_strings = [doc.page_content for doc in results]\n",
    "    doc_pages=[doc.metadata[\"page\"] for doc in results]\n",
    "    doc_s=list(np.unique(doc_strings))\n",
    "    doc_p=list(np.unique(doc_pages))\n",
    "    queries=[query]*len(doc_s)\n",
    "    pairs=[[queries[i], doc_s[i]] for i in range(len(doc_s))]\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(pairs, padding=True, truncation=True, return_tensors='pt', max_length=512).to(\"cuda\")\n",
    "        score_k = model(**inputs, return_dict=True).logits.view(-1, ).float()\n",
    "\n",
    "    scores=score_k.cpu().numpy()\n",
    "    df=pd.DataFrame([doc_s,doc_p,scores]).T\n",
    "    df.columns=[\"text\",\"page\",\"score\"]\n",
    "    df_sorted=df.sort_values(by='score', ascending=False)\n",
    "    df_sorted=df_sorted.reset_index(drop=True)\n",
    "    first_three_element = df_sorted.loc[0:2,\"text\"]\n",
    "    first_page=df_sorted.loc[0,\"page\"]\n",
    "    return first_three_element,first_page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCno3cMKDTtQ"
   },
   "source": [
    "#### retrieval qa with cross encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 623,
     "status": "ok",
     "timestamp": 1708168018994,
     "user": {
      "displayName": "Shirley Lin",
      "userId": "14721665985824307871"
     },
     "user_tz": -480
    },
    "id": "vOyoRxYs_P8T",
    "outputId": "63dc12f0-8976-4642-af7a-b0b6ba052ddc"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(temperature=0,\n",
    "    model_name=\"gpt-3.5-turbo-1106\",\n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    openai_api_base=os.environ[\"OPENAI_API_BASE\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1708159867945,
     "user": {
      "displayName": "Shirley Lin",
      "userId": "14721665985824307871"
     },
     "user_tz": -480
    },
    "id": "RFU5-vwA__ih"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "qa_system_prompt = \"\"\"你是一个汽车方面的专家，请结合给定的资料，并回答最终的问题。请如实回答，如果问题在资料中找不到答案，请回答不知道。\n",
    "资料：{context}\"\"\"\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1708159869893,
     "user": {
      "displayName": "Shirley Lin",
      "userId": "14721665985824307871"
     },
     "user_tz": -480
    },
    "id": "IqMyAXqmkkTi"
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "qa_chain = ({\"context\":RunnablePassthrough()  , \"question\": RunnablePassthrough()}\n",
    "    | qa_prompt\n",
    "    | llm\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1708168006078,
     "user": {
      "displayName": "Shirley Lin",
      "userId": "14721665985824307871"
     },
     "user_tz": -480
    },
    "id": "ZMt-D8PiDhiq"
   },
   "outputs": [],
   "source": [
    "questions = json.load(open(\"/gemini/data-1/questions.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(208,len(questions)):\n",
    "  query=questions[i][\"question\"]\n",
    "  first_three_element,first_page=create_documents(query)\n",
    "  questions[i][\"reference\"]=\"page_\"+str(first_page)\n",
    "  chunks=[]\n",
    "  for chunk in qa_chain.stream({\"context\":\"/n/n\".join(first_three_element),\"question\":query}):\n",
    "    chunks.append(chunk.content)\n",
    "  result=\"\".join(chunks)\n",
    "  questions[i]['answer'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type int64 is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Serializing json\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m json_object \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Writing to sample.json\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_openai_gbe_rerank.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m outfile:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/json/__init__.py:231\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# cached encoder\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m skipkeys \u001b[38;5;129;01mand\u001b[39;00m ensure_ascii \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     check_circular \u001b[38;5;129;01mand\u001b[39;00m allow_nan \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m separators \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sort_keys \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONEncoder\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/json/encoder.py:199\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    201\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/json/encoder.py:257\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     _iterencode \u001b[38;5;241m=\u001b[39m _make_iterencode(\n\u001b[1;32m    254\u001b[0m         markers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault, _encoder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent, floatstr,\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_keys,\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/json/encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    180\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type int64 is not JSON serializable"
     ]
    }
   ],
   "source": [
    "# Serializing json\n",
    "json_object = json.dumps(questions)\n",
    "\n",
    "# Writing to sample.json\n",
    "with open(\"sample_openai_gbe_rerank.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有点明白为什么之前就是使用一个doc来做的原因"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这边发现如果需要使用bge就一定需要使用这边的pre-train的情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMnYTEgYAtg0ViUGBFtJ6nL",
   "gpuType": "T4",
   "mount_file_id": "1tx_8B1dNgDR1uifdFG5qY8pRmXImh4QU",
   "provenance": [
    {
     "file_id": "1vvlU8dX22gAmRVb2twJ2EVIs4lqM7R5K",
     "timestamp": 1708158793077
    },
    {
     "file_id": "1ft8ZRd3DeBHVykm-WxTlIVHwlpfQWy8E",
     "timestamp": 1707710058838
    },
    {
     "file_id": "1GbTtda77LP_lmzbcMjdc6r-4RJZeYP0r",
     "timestamp": 1707120833061
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
