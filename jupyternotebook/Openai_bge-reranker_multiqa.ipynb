{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lg20GgWxJwso"
   },
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1708169396477,
     "user": {
      "displayName": "Shirley Lin",
      "userId": "14721665985824307871"
     },
     "user_tz": -480
    },
    "id": "CKQYdCW3RcMZ"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1708167503095,
     "user": {
      "displayName": "Shirley Lin",
      "userId": "14721665985824307871"
     },
     "user_tz": -480
    },
    "id": "bzVonL9yQ8yd"
   },
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"fk223678-Epq30sDYIn8TKUnTogD8C0Lu5QEF5bwx\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://oa.api2d.net/v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phGJxU2nJ0p2"
   },
   "source": [
    "### RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qUlHLSwkf6ED"
   },
   "source": [
    "##### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 405,
     "status": "ok",
     "timestamp": 1708168458827,
     "user": {
      "displayName": "Shirley Lin",
      "userId": "14721665985824307871"
     },
     "user_tz": -480
    },
    "id": "5rzC4dg-Jp1K"
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 8937,
     "status": "ok",
     "timestamp": 1708168469626,
     "user": {
      "displayName": "Shirley Lin",
      "userId": "14721665985824307871"
     },
     "user_tz": -480
    },
    "id": "D9_ODkxPJsum"
   },
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"/gemini/data-1/初赛训练数据集.pdf\")\n",
    "data=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 469,
     "status": "ok",
     "timestamp": 1708168484548,
     "user": {
      "displayName": "Shirley Lin",
      "userId": "14721665985824307871"
     },
     "user_tz": -480
    },
    "id": "mjfMWLpTg0Xa"
   },
   "outputs": [],
   "source": [
    "data_list=[]\n",
    "for i in range (0,len(data)):\n",
    "  page=data[i].metadata[\"page\"]\n",
    "  data[i].metadata[\"page\"]=page+1\n",
    "  if i>=2 and i<=6:\n",
    "    data[i].metadata[\"category\"]=\"catalog\"\n",
    "  else:\n",
    "    data[i].metadata[\"category\"]=\"content\"\n",
    "  if data[i].page_content!=\"\":\n",
    "    data_list.append(data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OUTFl5-kpaxW"
   },
   "source": [
    "我现在估计需要进行一下这边的预处理的工作。\n",
    "这边基本上都是没有加上任何的meta的。估计之后需要加上meta.\n",
    "注意这边的meta信息是不对的，因为这边的meta信息page是从0开始的，但是page的信息需要从1开始。所以这边有这样的一个page的更改。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_m1z5i9HN4jQ"
   },
   "source": [
    "这边我估计就是直接放弃所有的split的过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czMJ3hRhEGoO"
   },
   "source": [
    "##### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 9188,
     "status": "ok",
     "timestamp": 1708168547249,
     "user": {
      "displayName": "Shirley Lin",
      "userId": "14721665985824307871"
     },
     "user_tz": -480
    },
    "id": "K8xFpvZtQgR9"
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "vectordb = Chroma(persist_directory=\"/gemini/code/vectordb\", embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1708168547250,
     "user": {
      "displayName": "Shirley Lin",
      "userId": "14721665985824307871"
     },
     "user_tz": -480
    },
    "id": "bYd5_VW1SKRt",
    "outputId": "8ceec1f5-5f9e-4a8f-e95b-f6843db23fad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "334"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb._collection.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgWPU9Ilc3M9"
   },
   "source": [
    "#### 构建的retriever_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1708168547251,
     "user": {
      "displayName": "Shirley Lin",
      "userId": "14721665985824307871"
     },
     "user_tz": -480
    },
    "id": "O1SUefOkVNGS"
   },
   "outputs": [],
   "source": [
    "retriever_k =vectordb.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(temperature=0,\n",
    "    model_name=\"gpt-3.5-turbo-1106\",\n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    openai_api_base=os.environ[\"OPENAI_API_BASE\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "multiple_qa_system_prompt = \"\"\"你是一个汽车维修和汽车销售的专家，您的任务是将下列提问改写为5个含义相近但当不相同的句子。这些句子有不同的表现形式，但都是围绕着提问的主题。请提供这些替代问题，并用换行符分隔。\"\"\"\n",
    "multiple_qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", multiple_qa_system_prompt),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这边还有一个是AI方向的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_qa_chain = (multiple_qa_prompt| llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_original_query(query):\n",
    "    multiple_qa_system_prompt = \"\"\"你是一个汽车维修和汽车销售的专家，您的任务是将下列提问改写为5个含义相近但当不相同的句子。这些句子有不同的表现形式，但都是围绕着提问的主题。请提供这些替代问题，并用换行符分隔。\"\"\"\n",
    "    multiple_qa_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", multiple_qa_system_prompt),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ])\n",
    "    multiple_qa_chain = (multiple_qa_prompt| llm)\n",
    "    question_string = multiple_qa_chain.invoke({\"question\": query})\n",
    "    queries=question_string.content.splitlines()\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "感觉还行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"/gemini/pretrain\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/gemini/pretrain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_documents(query):\n",
    "    doc_list=[]\n",
    "    page_list=[]\n",
    "    query_list=[]\n",
    "\n",
    "    for q in queries:\n",
    "        results=retriever_k.get_relevant_documents(q)\n",
    "        doc_strings = [doc.page_content for doc in results]\n",
    "        doc_pages=[doc.metadata[\"page\"] for doc in results]\n",
    "        doc_s=list(np.unique(doc_strings))\n",
    "        doc_p=list(np.unique(doc_pages))\n",
    "        query_list.append([q]*len(doc_s))\n",
    "        doc_list.append(doc_s)\n",
    "        page_list.append(doc_p)\n",
    "\n",
    "    pairs=[]\n",
    "    for i in range(len(doc_list)):\n",
    "        docs=doc_list[i]\n",
    "        query_=query_list[i]\n",
    "        for j in range(len(docs)):\n",
    "            pairs.append([query_[j],docs[j]])\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(pairs, padding=True, truncation=True, return_tensors='pt').to(\"cuda\")\n",
    "        score_k = model(**inputs, return_dict=True).logits.view(-1, ).float()\n",
    "    scores=score_k.cpu().numpy()\n",
    "    df=pd.DataFrame([np.array(doc_list).flatten(),np.array(page_list).flatten(),scores]).T\n",
    "    df.columns=[\"text\",\"page\",\"score\"]\n",
    "    df.drop_duplicates(subset=['text'],inplace=True)\n",
    "    df_sorted=df.sort_values(by='score', ascending=False)\n",
    "    df_sorted=df_sorted.reset_index(drop=True)\n",
    "    first_element = df_sorted.loc[0,\"text\"]\n",
    "    first_page=df_sorted.loc[0,\"page\"]\n",
    "    return first_element,first_page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCno3cMKDTtQ"
   },
   "source": [
    "#### retrieval qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 623,
     "status": "ok",
     "timestamp": 1708168018994,
     "user": {
      "displayName": "Shirley Lin",
      "userId": "14721665985824307871"
     },
     "user_tz": -480
    },
    "id": "vOyoRxYs_P8T",
    "outputId": "63dc12f0-8976-4642-af7a-b0b6ba052ddc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(temperature=0,\n",
    "    model_name=\"gpt-3.5-turbo-1106\",\n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    openai_api_base=os.environ[\"OPENAI_API_BASE\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1708159867945,
     "user": {
      "displayName": "Shirley Lin",
      "userId": "14721665985824307871"
     },
     "user_tz": -480
    },
    "id": "RFU5-vwA__ih"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "qa_system_prompt = \"\"\"你是一个汽车方面的专家，请结合给定的资料，并回答最终的问题。请如实回答，如果问题在资料中找不到答案，请回答不知道。\n",
    "资料：{context}\"\"\"\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1708159869893,
     "user": {
      "displayName": "Shirley Lin",
      "userId": "14721665985824307871"
     },
     "user_tz": -480
    },
    "id": "IqMyAXqmkkTi"
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough,RunnableLambda\n",
    "chain = ({\"context\":RunnablePassthrough() , \"question\": RunnablePassthrough()}\n",
    "    | qa_prompt\n",
    "    | llm\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1708168006078,
     "user": {
      "displayName": "Shirley Lin",
      "userId": "14721665985824307871"
     },
     "user_tz": -480
    },
    "id": "ZMt-D8PiDhiq"
   },
   "outputs": [],
   "source": [
    "questions = json.load(open(\"/gemini/data-1/questions.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(questions)):\n",
    "  query=questions[i][\"question\"]\n",
    "  queries=create_original_query(query)\n",
    "  first_element,first_page=create_documents(queries)\n",
    "  questions[i][\"reference\"]=\"page_\"+str(first_page) \n",
    "  chunks=[]\n",
    "  for chunk in chain.stream({\"context\":first_element,\"question\":query}):\n",
    "    chunks.append(chunk.content)\n",
    "  result=\"\".join(chunks)\n",
    "  questions[i]['answer'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serializing json\n",
    "json_object = json.dumps(questions, indent=4)\n",
    "\n",
    "# Writing to sample.json\n",
    "with open(\"sample_openai-bge-reranker-multiqa.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "很神奇，就是query那边难道没有什么问题吗？会不会最终不是list?或者是还有什么多余的问题？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMnYTEgYAtg0ViUGBFtJ6nL",
   "gpuType": "T4",
   "mount_file_id": "1tx_8B1dNgDR1uifdFG5qY8pRmXImh4QU",
   "provenance": [
    {
     "file_id": "1vvlU8dX22gAmRVb2twJ2EVIs4lqM7R5K",
     "timestamp": 1708158793077
    },
    {
     "file_id": "1ft8ZRd3DeBHVykm-WxTlIVHwlpfQWy8E",
     "timestamp": 1707710058838
    },
    {
     "file_id": "1GbTtda77LP_lmzbcMjdc6r-4RJZeYP0r",
     "timestamp": 1707120833061
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
